{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from datetime import datetime as dt\n",
    "from scipy.signal import lfilter\n",
    "import pickle as pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6556, 9)\n"
     ]
    }
   ],
   "source": [
    "#cncb meta, need to match countries\n",
    "column_names = ['Virus Strain Name','Accession ID','Related ID','Nuc.Completeness','Sequence Quality','Host','Location','Sample Collection Date','Submitting Lab']\n",
    "meta = pd.read_excel('../metadata_B_1_1_7.xlsx',usecols=column_names,index_col=1)\n",
    "meta.fillna(' ',inplace=True)\n",
    "\n",
    "#Remove low quality and partial reads, pretty sure cncb does not run variant annotation for these anyways\n",
    "meta = meta[meta['Sequence Quality']!='Low']\n",
    "meta = meta[meta['Nuc.Completeness']!='Partial']\n",
    "\n",
    "#set country column and lowercase\n",
    "meta['Country'] = meta['Location'].str.split('/').str[0].str.strip()\n",
    "meta['Country'] = meta['Country'].str.lower()\n",
    "\n",
    "#Adjust country typos\n",
    "meta.loc[meta['Country']=='\\u200eromania','Country'] = 'romania'\n",
    "meta.loc[meta['Country']=='viet nam','Country'] = 'vietnam'\n",
    "meta.loc[meta['Country']=='czech repubic','Country'] = 'czech republic'\n",
    "meta.loc[meta['Country']=='ivory coast','Country'] = 'cotedivoire'\n",
    "\n",
    "# #Remove Crimea and Palestine\n",
    "meta = meta[meta['Country']!='crimea']\n",
    "meta = meta[meta['Country']!='palestine']\n",
    "\n",
    "print(meta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6556/6556 [04:20<00:00, 25.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_names = os.listdir('../gff3_cncb_restructured')\n",
    "column_names = ['variant type','start','end', 'info']\n",
    "missing = []\n",
    "aggregated_mutations = {}\n",
    "\n",
    "#for identifier in tqdm(meta[meta['Country']=='United States'].index):\n",
    "for identifier in tqdm(meta.index):\n",
    "    \n",
    "    #Searching for correct identifier\n",
    "    #--------------------------\n",
    "    #No alternate name is ' '\n",
    "    file_name = ''\n",
    "    #Check if accession id in file names, if not check related ids\n",
    "    if '2019-nCoV_'+identifier+'_variants.gff3' in all_names:\n",
    "        file_name = '2019-nCoV_'+identifier+'_variants.gff3'\n",
    "    # checking alternate names\n",
    "    elif meta.loc[identifier,'Related ID'] != ' ':\n",
    "        for alt_identifier in meta.loc[identifier,'Related ID'].replace(' ','').split(','):\n",
    "            if '2019-nCoV_'+alt_identifier+'_variants.gff3' in all_names:\n",
    "                file_name = '2019-nCoV_'+alt_identifier+'_variants.gff3'\n",
    "                break\n",
    "        #Added in case alternate names are also not found in gffs\n",
    "        if file_name == '':\n",
    "            missing.append(identifier)\n",
    "            continue\n",
    "    # If file name has not been updated, then there is no matching identifier, move to next index\n",
    "    elif file_name == '':\n",
    "        missing.append(identifier)\n",
    "        continue\n",
    "    #--------------------------\n",
    "    \n",
    "    #Filtering files with no variants\n",
    "    #--------------------------\n",
    "    with open(f'../gff3_cncb_restructured/{file_name}') as text_file:\n",
    "        lines = text_file.readlines()\n",
    "        counter = 0\n",
    "        for l in lines:\n",
    "            if '#' in l:\n",
    "                counter += 1\n",
    "    #Number of info lines should be less than total, if not then there are no mutations\n",
    "    #--------------------------\n",
    "    if counter<len(lines):\n",
    "        \n",
    "        gff = pd.read_csv(f'../gff3_cncb_restructured/{file_name}',sep='\\t',skiprows=counter,usecols=[1,3,4,8],names=column_names)\n",
    "        info_df = pd.DataFrame(gff['info'].str.split(';').values.tolist(),columns=[0,1,'Ref','Alt','Description']).drop([0,1],axis=1)\n",
    "        gff = gff.drop(['info'],axis=1)\n",
    "        gff['Country'] = [meta.loc[identifier,'Country']]*gff.shape[0]\n",
    "        temp_df = pd.concat([gff,info_df],axis=1)\n",
    "        \n",
    "        #Filtering alternate amino acid and reference for missense_variant and synonymous_variant\n",
    "        missenses_ref = temp_df.loc[temp_df['Description'].str.contains('missense_variant'),'Description'].str.split(',').str[1].str[-3]\n",
    "        synonymous_ref = temp_df.loc[temp_df['Description'].str.contains('synonymous_variant'),'Description'].str.split(',').str[1].str[-1]\n",
    "        temp_df['Ref_AA'] = pd.concat([missenses_ref,synonymous_ref])\n",
    "        temp_df['Alt_AA'] = temp_df.loc[temp_df['Description'].str.contains('missense_variant'),'Description'].str.split(',').str[1].str[-1]\n",
    "\n",
    "        missenses_str = temp_df.loc[temp_df['Description'].str.contains('missense_variant'),'Description'].str.split(',').str[1].str.split('.').str[-1]\n",
    "        synonymous_str = temp_df.loc[temp_df['Description'].str.contains('synonymous_variant'),'Description'].str.split(',').str[1].str.split('.').str[-1]\n",
    "        temp_df['AA'] = pd.concat([missenses_str,synonymous_str])\n",
    "        \n",
    "        temp_df.fillna('', inplace=True)\n",
    "        temp_df['descriptor'] = temp_df['start'].astype(str)+','+temp_df['end'].astype(str)+','+temp_df['Ref']+','+temp_df['Alt']+\\\n",
    "        ','+temp_df['Description'].str.split(',').str[0].str.split('=').str[1]+','+temp_df['variant type']+','+temp_df['Ref_AA']+','+temp_df['Alt_AA']+\\\n",
    "        ','+temp_df['AA']\n",
    "        \n",
    "        for var in temp_df['descriptor']:\n",
    "            if var not in aggregated_mutations.keys():\n",
    "                aggregated_mutations[var] = [[],[],[]]\n",
    "                \n",
    "            #Below numbers should be the same for each mutation of same file\n",
    "            #Country\n",
    "            aggregated_mutations[var][0].append(temp_df.loc[0,'Country'])\n",
    "\n",
    "print(len(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_muts = pd.DataFrame(list(aggregated_mutations.keys()),columns=['descriptor'])\n",
    "unique_muts = pd.DataFrame.join(unique_muts,pd.DataFrame(unique_muts['descriptor'].str.split(',').to_list())) #assign columns with parsed descriptor\n",
    "unique_muts.set_index('descriptor',inplace=True)\n",
    "unique_muts[0] = pd.to_numeric(unique_muts[0])\n",
    "unique_muts[1] = pd.to_numeric(unique_muts[1])\n",
    "unique_muts.sort_values([0,1],inplace=True)\n",
    "unique_muts.columns = ['Start','End','Ref','Alt','VEP','Variant Type','Ref_AA','Alt_AA','AA']\n",
    "\n",
    "\n",
    "counts = {}\n",
    "num_countries = {}\n",
    "counted_countries = {}\n",
    "\n",
    "for desc in unique_muts.index:\n",
    "    counts[desc] = len(aggregated_mutations[desc][0])\n",
    "    num_countries[desc] = len(set(aggregated_mutations[desc][0]))\n",
    "    counted_countries[desc] = dict(Counter(aggregated_mutations[desc][0]))\n",
    "        \n",
    "unique_muts['counts'] = unique_muts.index.to_series().map(counts)\n",
    "unique_muts['countries'] = unique_muts.index.to_series().map(num_countries)\n",
    "unique_muts['counted_countries'] = unique_muts.index.to_series().map(counted_countries)\n",
    "unique_muts.index = unique_muts.index.str.split(',').str[0:4].str.join('_')\n",
    "unique_muts.to_csv(f\"B_1_1_7_variants.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.8_misc]",
   "language": "python",
   "name": "conda-env-py3.8_misc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
